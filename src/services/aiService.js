/**
 * AI æœåŠ¡
 * è´Ÿè´£è°ƒç”¨å¤–éƒ¨ AI æ¨¡å‹ç”Ÿæˆä»£ç 
 */

/**
 * è°ƒç”¨ AI ç”Ÿæˆä»£ç 
 * @param {Object} params - å‚æ•°
 * @param {string} params.prompt - Prompt æ–‡æœ¬
 * @param {Object} params.aiConfig - AI é…ç½®
 * @returns {Promise<string>} ç”Ÿæˆçš„ä»£ç 
 */
export async function callAIGenerate({ prompt, aiConfig }) {
  const { baseUrl, apiKey, model, temperature, maxTokens } = aiConfig

  if (!baseUrl || !apiKey) {
    throw new Error('AI é…ç½®ä¸å®Œæ•´ï¼Œè¯·å…ˆé…ç½® Base URL å’Œ API Key')
  }

  try {
    console.log('ğŸ¤– Calling AI model:', model)
    console.log('ğŸ“ Prompt length:', prompt.length, 'characters')

    const response = await fetch(`${baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model,
        messages: [
          {
            role: 'system',
            content: `ä½ æ˜¯ä¸€ä¸ª Vue2 ä»£ç ç”Ÿæˆä¸“å®¶ï¼Œä¸“æ³¨äºä½¿ç”¨ hui2.43.2 + hui-pro ç»„ä»¶åº“ç”Ÿæˆé«˜è´¨é‡çš„é¡µé¢ä»£ç ã€‚

ä½ çš„ä»»åŠ¡ï¼š
1. ä¸¥æ ¼å‚è€ƒæä¾›çš„ Handlebars æ¨¡æ¿ç»“æ„
2. æ ¹æ® API JSON ç¤ºä¾‹æ¨æ–­å­—æ®µæ˜ å°„å’Œæ•°æ®è·¯å¾„
3. æ ¹æ®ç»„ä»¶é…ç½®ç”Ÿæˆå®Œæ•´çš„ Vue2 Options API ä»£ç 
4. ç¡®ä¿ä»£ç ç¬¦åˆ hui2.43.2 + hui-pro è§„èŒƒ

ä»£ç è§„èŒƒï¼š
- ä½¿ç”¨ Vue2 Options API
- ä½¿ç”¨ <script> (ä¸ä½¿ç”¨ setup)
- ä½¿ç”¨ data() è¿”å›æ•°æ®
- ä½¿ç”¨ methods å®šä¹‰æ–¹æ³•
- ä½¿ç”¨ mounted() ç”Ÿå‘½å‘¨æœŸ
- ä½¿ç”¨ hui-pro é¡µé¢ç»„ä»¶ï¼ˆh-page-container, h-page-search, etcï¼‰
- ä½¿ç”¨ hui2.43.2 åŸºç¡€ç»„ä»¶ï¼ˆel-input, el-select, etcï¼‰

åªè¿”å›å®Œæ•´çš„ .vue æ–‡ä»¶ä»£ç ï¼Œä¸è¦æœ‰ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–è¯´æ˜ã€‚`,
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        temperature,
        max_tokens: maxTokens,
      }),
    })

    if (!response.ok) {
      const error = await response.json().catch(() => ({}))
      throw new Error(
        `AI API è°ƒç”¨å¤±è´¥: ${response.status} ${response.statusText}${error.error?.message ? ` - ${error.error.message}` : ''}`
      )
    }

    const data = await response.json()
    console.log('âœ… AI response received')

    if (!data.choices || data.choices.length === 0) {
      throw new Error('AI è¿”å›æ•°æ®æ ¼å¼é”™è¯¯ï¼šæ²¡æœ‰ choices')
    }

    const code = data.choices[0].message.content
    if (!code) {
      throw new Error('AI è¿”å›æ•°æ®æ ¼å¼é”™è¯¯ï¼šæ²¡æœ‰ content')
    }

    console.log('ğŸ“„ Generated code length:', code.length, 'characters')

    // æ¸…ç†ä»£ç ï¼ˆç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°ï¼‰
    let cleanedCode = code.trim()
    if (cleanedCode.startsWith('```vue')) {
      cleanedCode = cleanedCode.replace(/^```vue\n/, '').replace(/\n```$/, '')
    } else if (cleanedCode.startsWith('```')) {
      cleanedCode = cleanedCode.replace(/^```\n/, '').replace(/\n```$/, '')
    }

    return cleanedCode
  } catch (error) {
    console.error('âŒ AI generation error:', error)
    throw error
  }
}

/**
 * æµ‹è¯• AI è¿æ¥
 * @param {Object} aiConfig - AI é…ç½®
 * @returns {Promise<boolean>} æ˜¯å¦è¿æ¥æˆåŠŸ
 */
export async function testAIConnection(aiConfig) {
  const { baseUrl, apiKey, model } = aiConfig

  if (!baseUrl || !apiKey) {
    throw new Error('AI é…ç½®ä¸å®Œæ•´')
  }

  try {
    const response = await fetch(`${baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model,
        messages: [
          {
            role: 'user',
            content: 'test',
          },
        ],
        max_tokens: 5,
      }),
    })

    return response.ok
  } catch (error) {
    console.error('AI connection test failed:', error)
    return false
  }
}

/**
 * AI å¯¹è¯
 * @param {Object} params
 * @param {Array} params.messages - èŠå¤©æ¶ˆæ¯æ•°ç»„
 * @param {Object} params.aiConfig - AI é…ç½®
 * @returns {Promise<string>} AI å›å¤å†…å®¹
 */
export async function sendChatMessages({ messages, aiConfig }) {
  const { baseUrl, apiKey, model, temperature, maxTokens } = aiConfig

  if (!baseUrl || !apiKey) {
    throw new Error('AI é…ç½®ä¸å®Œæ•´ï¼Œè¯·å…ˆé…ç½® Base URL å’Œ API Key')
  }

  try {
    const response = await fetch(`${baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model,
        messages,
        temperature,
        max_tokens: Math.min(maxTokens || 4000, 4000),
      }),
    })

    if (!response.ok) {
      const error = await response.json().catch(() => ({}))
      throw new Error(
        `AI å¯¹è¯å¤±è´¥: ${response.status} ${response.statusText}${
          error.error?.message ? ` - ${error.error.message}` : ''
        }`
      )
    }

    const data = await response.json()
    const assistantMessage = data.choices?.[0]?.message?.content

    if (!assistantMessage) {
      throw new Error('AI è¿”å›æ•°æ®æ ¼å¼é”™è¯¯ï¼šæ²¡æœ‰ content')
    }

    return assistantMessage.trim()
  } catch (error) {
    console.error('âŒ AI chat error:', error)
    throw error
  }
}

